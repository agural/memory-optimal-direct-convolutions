{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST - Training\n",
    "\n",
    "Given the optimal architecture that meets the memory constraints, train it (first floating point, then quantized). For small networks, bad initializations and training steps appear to be especially problematic. So we run each of these main training steps several times and choose the result that maximizes performance on the validation set. We run the final quantized network on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import os, sys, pdb, pickle\n",
    "from itertools import product\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Model, Sequential, load_model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten, Conv2D, MaxPooling2D, AveragePooling2D, Lambda, Activation, Add, concatenate\n",
    "from keras.callbacks import LearningRateScheduler, ModelCheckpoint\n",
    "from keras.engine.topology import Layer\n",
    "from keras import regularizers, activations\n",
    "from keras import backend as K\n",
    "\n",
    "from quantization_layers import *\n",
    "from network_parameterization import *\n",
    "\n",
    "#os.environ['CUDA_VISIBLE_DEVICES']=''\n",
    "\n",
    "out_folder = 'models'\n",
    "if not os.path.exists(out_folder):\n",
    "    os.makedirs(out_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data and network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 28, 28, 1)\n",
      "200000 train samples\n",
      "10000 val samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "num_classes = 10\n",
    "\n",
    "# Grab and massage the training and test data.\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "img_rows, img_cols = x_train.shape[1:3]\n",
    "\n",
    "x_train = x_train.astype('float32') / 256\n",
    "x_test  = x_test.astype('float32')  / 256\n",
    "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "x_test  = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "np.random.seed(0)\n",
    "val_set = np.zeros(x_train.shape[0], dtype='bool')\n",
    "val_set[np.random.choice(x_train.shape[0], 10000, replace=False)] = 1\n",
    "x_val = x_train[val_set]\n",
    "y_val = y_train[val_set]\n",
    "x_train = x_train[~val_set]\n",
    "y_train = y_train[~val_set]\n",
    "\n",
    "with open('augmented_x_200k_v2.npy', 'rb') as f:\n",
    "    x_train_aug = np.load(f) * 255 / 256\n",
    "with open('augmented_y_200k_v2.npy', 'rb') as f:\n",
    "    y_train_aug = np.load(f)\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train_aug.shape[0], 'train samples')\n",
    "print(x_val.shape[0], 'val samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1947B] - Network: [('A', 2, 4), ('C', 5, 3, 3, 1, 1, 4, 8, 4), ('C', 8, 3, 3, 1, 1, 4, 8, 4), ('C', 11, 3, 3, 1, 1, 4, 8, 4), ('M', 2, 4), ('D', 0.1, 4), ('S', 10, 4, 8, 8)]\n"
     ]
    }
   ],
   "source": [
    "config = [('A', 2, 4), ('C', 5, 3, 3, 1, 1, 4, 8, 4), ('C', 8, 3, 3, 1, 1, 4, 8, 4), ('C', 11, 3, 3, 1, 1, 4, 8, 4), ('M', 2, 4), ('D', 0.1, 4), ('S', 10, 4, 8, 8)]\n",
    "storage = sum(compute_storage(config, input_dimensions=[28,28,1], input_bits=8, streaming='true', convolution_strategy='herringbone'))\n",
    "print('[%04dB] - Network:'%storage, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run floating point training\n",
    "\n",
    "Find the best FP32 network over 10 training sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "On trial 1/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0304 - accuracy: 0.9905\n",
      "Model F Validation loss: 0.0304 - accuracy: 0.9902\n",
      "\n",
      "\n",
      "On trial 2/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0328 - accuracy: 0.9905\n",
      "Model F Validation loss: 0.0328 - accuracy: 0.9896\n",
      "\n",
      "\n",
      "On trial 3/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0381 - accuracy: 0.9892\n",
      "Model F Validation loss: 0.0381 - accuracy: 0.9889\n",
      "\n",
      "\n",
      "On trial 4/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0331 - accuracy: 0.9904\n",
      "Model F Validation loss: 0.0331 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "On trial 5/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0381 - accuracy: 0.9894\n",
      "Model F Validation loss: 0.0381 - accuracy: 0.9890\n",
      "\n",
      "\n",
      "On trial 6/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0340 - accuracy: 0.9892\n",
      "Model F Validation loss: 0.0340 - accuracy: 0.9888\n",
      "\n",
      "\n",
      "On trial 7/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0328 - accuracy: 0.9906\n",
      "Model F Validation loss: 0.0328 - accuracy: 0.9903\n",
      "\n",
      "\n",
      "On trial 8/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0364 - accuracy: 0.9896\n",
      "Model F Validation loss: 0.0364 - accuracy: 0.9894\n",
      "\n",
      "\n",
      "On trial 9/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0334 - accuracy: 0.9903\n",
      "Model F Validation loss: 0.0334 - accuracy: 0.9900\n",
      "\n",
      "\n",
      "On trial 10/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0341 - accuracy: 0.9898\n",
      "Model F Validation loss: 0.0341 - accuracy: 0.9894\n",
      "\n",
      "\n",
      "On trial 11/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0356 - accuracy: 0.9897\n",
      "Model F Validation loss: 0.0356 - accuracy: 0.9897\n",
      "\n",
      "\n",
      "On trial 12/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0372 - accuracy: 0.9896\n",
      "Model F Validation loss: 0.0372 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "On trial 13/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0398 - accuracy: 0.9884\n",
      "Model F Validation loss: 0.0398 - accuracy: 0.9879\n",
      "\n",
      "\n",
      "On trial 14/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0353 - accuracy: 0.9906\n",
      "Model F Validation loss: 0.0353 - accuracy: 0.9884\n",
      "\n",
      "\n",
      "On trial 15/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0333 - accuracy: 0.9901\n",
      "Model F Validation loss: 0.0333 - accuracy: 0.9897\n",
      "\n",
      "\n",
      "On trial 16/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0358 - accuracy: 0.9893\n",
      "Model F Validation loss: 0.0358 - accuracy: 0.9883\n",
      "\n",
      "\n",
      "On trial 17/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "\n",
      "\n",
      "On trial 18/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0341 - accuracy: 0.9898\n",
      "Model F Validation loss: 0.0341 - accuracy: 0.9895\n",
      "\n",
      "\n",
      "On trial 19/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0357 - accuracy: 0.9897\n",
      "Model F Validation loss: 0.0357 - accuracy: 0.9891\n",
      "\n",
      "\n",
      "On trial 20/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0378 - accuracy: 0.9887\n",
      "Model F Validation loss: 0.0378 - accuracy: 0.9886\n",
      "\n",
      "\n",
      "On trial 21/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0373 - accuracy: 0.9896\n",
      "Model F Validation loss: 0.0373 - accuracy: 0.9895\n",
      "\n",
      "\n",
      "On trial 22/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0377 - accuracy: 0.9888\n",
      "Model F Validation loss: 0.0377 - accuracy: 0.9876\n",
      "\n",
      "\n",
      "On trial 23/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0379 - accuracy: 0.9883\n",
      "Model F Validation loss: 0.0379 - accuracy: 0.9883\n",
      "\n",
      "\n",
      "On trial 24/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0379 - accuracy: 0.9895\n",
      "Model F Validation loss: 0.0379 - accuracy: 0.9888\n",
      "\n",
      "\n",
      "On trial 25/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0373 - accuracy: 0.9888\n",
      "Model F Validation loss: 0.0373 - accuracy: 0.9883\n",
      "\n",
      "\n",
      "On trial 26/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0353 - accuracy: 0.9898\n",
      "Model F Validation loss: 0.0353 - accuracy: 0.9895\n",
      "\n",
      "\n",
      "On trial 27/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0336 - accuracy: 0.9901\n",
      "Model F Validation loss: 0.0336 - accuracy: 0.9901\n",
      "\n",
      "\n",
      "On trial 28/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0342 - accuracy: 0.9905\n",
      "Model F Validation loss: 0.0342 - accuracy: 0.9899\n",
      "\n",
      "\n",
      "On trial 29/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0374 - accuracy: 0.9900\n",
      "Model F Validation loss: 0.0374 - accuracy: 0.9894\n",
      "\n",
      "\n",
      "On trial 30/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0364 - accuracy: 0.9894\n",
      "Model F Validation loss: 0.0364 - accuracy: 0.9885\n",
      "\n",
      "\n",
      "On trial 31/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0342 - accuracy: 0.9897\n",
      "Model F Validation loss: 0.0342 - accuracy: 0.9894\n",
      "\n",
      "\n",
      "On trial 32/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0333 - accuracy: 0.9898\n",
      "Model F Validation loss: 0.0333 - accuracy: 0.9895\n",
      "\n",
      "\n",
      "On trial 33/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0343 - accuracy: 0.9883\n",
      "Model F Validation loss: 0.0343 - accuracy: 0.9880\n",
      "\n",
      "\n",
      "On trial 34/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0347 - accuracy: 0.9906\n",
      "Model F Validation loss: 0.0347 - accuracy: 0.9905\n",
      "\n",
      "\n",
      "On trial 35/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0351 - accuracy: 0.9894\n",
      "Model F Validation loss: 0.0351 - accuracy: 0.9887\n",
      "\n",
      "\n",
      "On trial 36/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0359 - accuracy: 0.9899\n",
      "Model F Validation loss: 0.0359 - accuracy: 0.9895\n",
      "\n",
      "\n",
      "On trial 37/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0320 - accuracy: 0.9901\n",
      "Model F Validation loss: 0.0320 - accuracy: 0.9897\n",
      "\n",
      "\n",
      "On trial 38/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0308 - accuracy: 0.9912\n",
      "Model F Validation loss: 0.0308 - accuracy: 0.9907\n",
      "\n",
      "\n",
      "On trial 39/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0386 - accuracy: 0.9890\n",
      "Model F Validation loss: 0.0386 - accuracy: 0.9887\n",
      "\n",
      "\n",
      "On trial 40/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0321 - accuracy: 0.9896\n",
      "Model F Validation loss: 0.0321 - accuracy: 0.9896\n",
      "\n",
      "\n",
      "On trial 41/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0358 - accuracy: 0.9897\n",
      "Model F Validation loss: 0.0358 - accuracy: 0.9890\n",
      "\n",
      "\n",
      "On trial 42/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0319 - accuracy: 0.9894\n",
      "Model F Validation loss: 0.0319 - accuracy: 0.9891\n",
      "\n",
      "\n",
      "On trial 43/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0316 - accuracy: 0.9914\n",
      "Model F Validation loss: 0.0316 - accuracy: 0.9914\n",
      "\n",
      "\n",
      "On trial 44/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0401 - accuracy: 0.9895\n",
      "Model F Validation loss: 0.0401 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "On trial 45/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0330 - accuracy: 0.9905\n",
      "Model F Validation loss: 0.0330 - accuracy: 0.9901\n",
      "\n",
      "\n",
      "On trial 46/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0359 - accuracy: 0.9896\n",
      "Model F Validation loss: 0.0359 - accuracy: 0.9890\n",
      "\n",
      "\n",
      "On trial 47/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0351 - accuracy: 0.9905\n",
      "Model F Validation loss: 0.0351 - accuracy: 0.9896\n",
      "\n",
      "\n",
      "On trial 48/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0333 - accuracy: 0.9899\n",
      "Model F Validation loss: 0.0333 - accuracy: 0.9897\n",
      "\n",
      "\n",
      "On trial 49/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0356 - accuracy: 0.9896\n",
      "Model F Validation loss: 0.0356 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "On trial 50/50:\n",
      "#param: 3003\n",
      "Best Validation loss: 0.0333 - accuracy: 0.9902\n",
      "Model F Validation loss: 0.0333 - accuracy: 0.9901\n",
      "\n",
      "\n",
      "\n",
      "Best Validation Accuracy: 0.9916\n"
     ]
    }
   ],
   "source": [
    "trials = 50\n",
    "best_acc = 0\n",
    "for trial in range(trials):\n",
    "    print('\\n\\nOn trial %d/%d:'%(trial+1, trials))\n",
    "    lrate95 = LearningRateScheduler(lambda epoch: max(1e-4, 0.005 * 0.95**epoch))\n",
    "    ckptL = ModelCheckpoint(out_folder + '/modelFL_%d.h5'%trial, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "    ckptA = ModelCheckpoint(out_folder + '/modelFA_%d.h5'%trial, monitor='val_acc', verbose=0, save_best_only=True)\n",
    "    \n",
    "    X_input = Input(shape=x_train.shape[1:])\n",
    "    X = output_logits(X_input, config, fp=True, qt=0)\n",
    "    X = Activation('softmax')(X)\n",
    "    modelF = Model(X_input, X)\n",
    "    modelF.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    print('#param:', modelF.count_params())\n",
    "    histf = modelF.fit(x_train_aug, y_train_aug, batch_size=1024, epochs=50, callbacks=[lrate95, ckptA, ckptL], verbose=0, validation_data=(x_val, y_val))\n",
    "    \n",
    "    modelF = load_model(out_folder + '/modelFL_%d.h5'%trial, custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "    score = modelF.evaluate(x_val, y_val, verbose=0)\n",
    "    cur_acc = np.max(histf.history['val_acc'])\n",
    "    print('Best Validation loss: %.4f - accuracy: %.4f'%(np.min(histf.history['val_loss']), cur_acc))\n",
    "    print('Model F Validation loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        modelF.save(out_folder + '/modelFL_best.h5')\n",
    "        modelF = load_model(out_folder + '/modelFA_%d.h5'%trial, custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "        modelF.save(out_folder + '/modelFA_best.h5')\n",
    "print('\\n\\n\\nBest Validation Accuracy: %.4f'%best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run quantized training twice\n",
    "\n",
    "1. First run - find the best quantized network over 10 training sessions while allowing quantization scales to move.\n",
    "2. Second run - find the best quantized network over 10 training sessions while freezing quantization scales (allows more stable convergence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "On trial 1/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0349 - accuracy: 0.9894\n",
      "Model Validation loss: 0.0349 - accuracy: 0.9887\n",
      "\n",
      "\n",
      "\n",
      "On trial 2/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0377 - accuracy: 0.9892\n",
      "Model Validation loss: 0.0377 - accuracy: 0.9884\n",
      "\n",
      "\n",
      "\n",
      "On trial 3/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0357 - accuracy: 0.9892\n",
      "Model Validation loss: 0.0357 - accuracy: 0.9889\n",
      "\n",
      "\n",
      "\n",
      "On trial 4/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0369 - accuracy: 0.9893\n",
      "Model Validation loss: 0.0369 - accuracy: 0.9893\n",
      "\n",
      "\n",
      "\n",
      "On trial 5/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0352 - accuracy: 0.9897\n",
      "Model Validation loss: 0.0352 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "\n",
      "On trial 6/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0365 - accuracy: 0.9889\n",
      "Model Validation loss: 0.0365 - accuracy: 0.9888\n",
      "\n",
      "\n",
      "\n",
      "On trial 7/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0365 - accuracy: 0.9892\n",
      "Model Validation loss: 0.0365 - accuracy: 0.9887\n",
      "\n",
      "\n",
      "\n",
      "On trial 8/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0362 - accuracy: 0.9900\n",
      "Model Validation loss: 0.0362 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "\n",
      "On trial 9/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0372 - accuracy: 0.9893\n",
      "Model Validation loss: 0.0372 - accuracy: 0.9881\n",
      "\n",
      "\n",
      "\n",
      "On trial 10/10:\n",
      "Model F Validation loss: 0.0335 - accuracy: 0.9916\n",
      "Quantization layer 3: w(-0.0477 +/- 0.7150) b(0.2804 +/- 0.1756) qw(1.6116) qb(1.1171) qa(1.9521)\n",
      "Quantization layer 4: w(0.0133 +/- 0.4118) b(0.0412 +/- 0.2700) qw(1.0611) qb(1.1542) qa(4.7224)\n",
      "Quantization layer 5: w(-0.0514 +/- 0.3263) b(0.1365 +/- 0.2259) qw(0.8358) qb(1.4945) qa(6.5495)\n",
      "Quantization layer 9: w(-0.0225 +/- 0.2671) b(0.0134 +/- 0.3728) qw(0.7327) qb(1.7259) qa(23.9298)\n",
      "Best Validation loss: 0.0363 - accuracy: 0.9894\n",
      "Model Validation loss: 0.0363 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "\n",
      "Best Validation Accuracy: 0.9900\n"
     ]
    }
   ],
   "source": [
    "trials = 10\n",
    "best_acc = 0\n",
    "for trial in range(trials):\n",
    "    print('\\n\\n\\nOn trial %d/%d:'%(trial+1, trials))\n",
    "    modelF = load_model(out_folder + '/modelFL_best.h5', custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "    score = modelF.evaluate(x_val, y_val, verbose=0)\n",
    "    print('Model F Validation loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "    \n",
    "    lrate98 = LearningRateScheduler(lambda epoch: max(1e-4, 0.005 * 0.98**epoch))\n",
    "    ckptL = ModelCheckpoint(out_folder + '/modelTL_%d.h5'%trial, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "    ckptA = ModelCheckpoint(out_folder + '/modelTA_%d.h5'%trial, monitor='val_acc', verbose=0, save_best_only=True)\n",
    "    X_input = Input(shape=x_train.shape[1:])\n",
    "    X = output_logits(X_input, config, fp=False, qt=1)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(X_input, X)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    loadQ(modelF, model, x_val, verbose=True)\n",
    "    histL = model.fit(x_train_aug, y_train_aug, batch_size=1024, epochs=100, callbacks=[lrate98, ckptA, ckptL], verbose=0, validation_data=(x_val, y_val))\n",
    "\n",
    "    model = load_model(out_folder + '/modelTL_%d.h5'%trial, custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    cur_acc = np.max(histL.history['val_acc'])\n",
    "    print('Best Validation loss: %.4f - accuracy: %.4f'%(np.min(histL.history['val_loss']), cur_acc))\n",
    "    print('Model Validation loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        model.save(out_folder + '/modelTL_best.h5')\n",
    "        model = load_model(out_folder + '/modelTA_%d.h5'%trial, custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "        model.save(out_folder + '/modelTA_best.h5')\n",
    "print('\\n\\n\\nBest Validation Accuracy: %.4f'%best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "On trial 1/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0335 - accuracy: 0.9909\n",
      "Model Validation loss: 0.0335 - accuracy: 0.9909\n",
      "\n",
      "\n",
      "\n",
      "On trial 2/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0345 - accuracy: 0.9904\n",
      "Model Validation loss: 0.0345 - accuracy: 0.9899\n",
      "\n",
      "\n",
      "\n",
      "On trial 3/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0346 - accuracy: 0.9906\n",
      "Model Validation loss: 0.0346 - accuracy: 0.9904\n",
      "\n",
      "\n",
      "\n",
      "On trial 4/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0349 - accuracy: 0.9904\n",
      "Model Validation loss: 0.0349 - accuracy: 0.9890\n",
      "\n",
      "\n",
      "\n",
      "On trial 5/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0343 - accuracy: 0.9907\n",
      "Model Validation loss: 0.0343 - accuracy: 0.9900\n",
      "\n",
      "\n",
      "\n",
      "On trial 6/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0359 - accuracy: 0.9907\n",
      "Model Validation loss: 0.0359 - accuracy: 0.9892\n",
      "\n",
      "\n",
      "\n",
      "On trial 7/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0351 - accuracy: 0.9906\n",
      "Model Validation loss: 0.0351 - accuracy: 0.9903\n",
      "\n",
      "\n",
      "\n",
      "On trial 8/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0352 - accuracy: 0.9911\n",
      "Model Validation loss: 0.0352 - accuracy: 0.9902\n",
      "\n",
      "\n",
      "\n",
      "On trial 9/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0347 - accuracy: 0.9906\n",
      "Model Validation loss: 0.0347 - accuracy: 0.9885\n",
      "\n",
      "\n",
      "\n",
      "On trial 10/10:\n",
      "Model L Validation loss: 0.0362 - accuracy: 0.9892\n",
      "Best Validation loss: 0.0346 - accuracy: 0.9905\n",
      "Model Validation loss: 0.0346 - accuracy: 0.9903\n",
      "\n",
      "\n",
      "\n",
      "Best Validation Accuracy: 0.9911\n"
     ]
    }
   ],
   "source": [
    "trials = 10\n",
    "best_acc = 0\n",
    "for trial in range(trials):\n",
    "    print('\\n\\n\\nOn trial %d/%d:'%(trial+1, trials))\n",
    "    modelL = load_model(out_folder + '/modelTL_best.h5', custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "    score = modelL.evaluate(x_val, y_val, verbose=0)\n",
    "    print('Model L Validation loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "    modelL.save_weights('temp.h5')\n",
    "\n",
    "    lrate98 = LearningRateScheduler(lambda epoch: max(1e-4, 0.005 * 0.98**epoch))\n",
    "    ckptA = ModelCheckpoint(out_folder + '/modelQA_%d.h5'%trial, monitor='val_acc', verbose=0, save_best_only=True)\n",
    "    ckptL = ModelCheckpoint(out_folder + '/modelQL_%d.h5'%trial, monitor='val_loss', verbose=0, save_best_only=True)\n",
    "    X_input = Input(shape=x_train.shape[1:])\n",
    "    X = output_logits(X_input, config, fp=False, qt=0)\n",
    "    X = Activation('softmax')(X)\n",
    "    model = Model(X_input, X)\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy, optimizer=keras.optimizers.Adam(), metrics=['accuracy'])\n",
    "    model.load_weights('temp.h5')\n",
    "    histq = model.fit(x_train_aug, y_train_aug, batch_size=1024, epochs=200, callbacks=[lrate98, ckptA, ckptL], verbose=0, validation_data=(x_val, y_val))\n",
    "    model = load_model(out_folder + '/modelQL_%d.h5'%trial, custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "    \n",
    "    score = model.evaluate(x_val, y_val, verbose=0)\n",
    "    cur_acc = np.max(histq.history['val_acc'])\n",
    "    print('Best Validation loss: %.4f - accuracy: %.4f'%(np.min(histq.history['val_loss']), cur_acc))\n",
    "    print('Model Validation loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        model.save(out_folder + '/modelQL_best.h5')\n",
    "        model = load_model(out_folder + '/modelQA_%d.h5'%trial, custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "        model.save(out_folder + '/modelQA_best.h5')\n",
    "print('\\n\\n\\nBest Validation Accuracy: %.4f'%best_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the test set\n",
    "\n",
    "Note: we manually selected the model that had both high accuracy and low loss according to:\n",
    "\n",
    "$\\max_i \\frac{\\sigma_a^2}{\\sigma^2 + \\sigma_a^2} z_a^{(i)} - z_\\ell^{(i)}$\n",
    "\n",
    "where $z_a^{(i)}$ is the z-score of the $i^\\text{th}$ accuracy and $z_\\ell^{(i)}$ is the z-score of the $i^\\text{th}$ loss. $\\sigma = \\sqrt{p(1-p)/M} \\approx 10^{-3}$ is the standard deviation of accuracy on the test set, calculated by assuming test samples are Bernoulli random variates with $p = \\text{average accuracy}$. $\\sigma_a$ is the approximate uncertainty (standard deviation) of accuracy around a given loss value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss: 0.0335 - accuracy: 0.9909\n",
      "Test       loss: 0.0295 - accuracy: 0.9916\n",
      "1947B - 99.16% - Network: [('A', 2, 4), ('C', 5, 3, 3, 1, 1, 4, 8, 4), ('C', 8, 3, 3, 1, 1, 4, 8, 4), ('C', 11, 3, 3, 1, 1, 4, 8, 4), ('M', 2, 4), ('D', 0.1, 4), ('S', 10, 4, 8, 8)]\n"
     ]
    }
   ],
   "source": [
    "# Run the test accuracy\n",
    "\n",
    "model = load_model(out_folder + '/modelQL_0.h5', custom_objects={'DenseQ':DenseQ, 'ConvQ':ConvQ, 'ResidQ':ResidQ, 'quantize':quantize, 'concatenate':concatenate})\n",
    "score = model.evaluate(x_val, y_val, verbose=0)\n",
    "print('Validation loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test       loss: %.4f - accuracy: %.4f'%(score[0], score[1]))\n",
    "print('%04dB - %05.2f%% - Network:'%(storage, 100*score[1]), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
